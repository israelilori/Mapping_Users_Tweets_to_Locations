installed.packages("twitteR")
installed.packages("ROAuth")
installed.packages("twitteR")
installed.packages("ROAuth")
library(twitteR)
library(ROAuth)
installed.packages("twitteR")
installed.packages("ROAuth")
installed.packages("twitteR")
installed.packages("ROAuth")
library(twitteR)
library(ROAuth)
setwd("~/Text Mining/Coursework 2")
#----Showing the locations of the users talking about the candidates
# install relevant packages
install.packages("twitteR")
install.packages("ROAuth")
install.packages("RJSONIO")
install.packages("data.table")
install.packages("leaflet")
library(twitteR)
library(ROAuth)
library(RJSONIO)
library(leaflet)
library(data.table)
# authenticate with Twitter
consumerKey<-	"gqOGypzh3PPHPsdYsSA8XVxw3"
consumerSecret<-"lrkmNz3Ev4zlekYpgt47lM22g23ZT3LTDHdv1eIzH6djXGu1Ze"
accessToken<-"1091711245315641344-RJ82bw7Brx3m4gnw1hrcx7qMLohi6n"
accessSecret<-"OponAQ4utL3ihKlMEe4pEQJoRUT5py2j5Vcg2CMjDyqWP"
setup_twitter_oauth (consumerKey, consumerSecret, accessToken, accessSecret)  # authenticate
#For Candidate Julian Castro
#Read in the file into R
castro <- read.csv("Castro_keyword.csv", header = TRUE)
#Get the location of the candidate via their profile
user<-getUser("JulianCastro")
user$location
#Set the users location from their profile to empty so we can save into it
castro$user_location_on_twitter_bio <- NA
#loop over the various tweets and their users in the dataframe #this was done for the first 200 tweets
for (user in castro$screen_name[1:200]){
print(c("finding the profile for:",user))
Sys.sleep(3) #build in a sleeper to prevent Twitter API rate limit error.
try(castro[castro$screen_name==user,]$user_location_on_twitter_bio <- getUser(user)$location)
}
#Linking google earth platform locator so as to correlate with users location on the earth
castro$lat <- NA
castro$lng <- NA
source("https://raw.githubusercontent.com/LucasPuente/geocoding/master/geocode_helpers.R")
source("https://raw.githubusercontent.com/LucasPuente/geocoding/master/modified_geocode.R")
geocode_apply<-function(x){
geocode(x, source = "google", output = "all", api_key="AIzaSyDgba3BMFysxhuE8Mi8EkAMoko_fIiJZPk")
}
#create a dataframe for tweets with geo location informations
castro_withgeo <- castro[castro$user_location_on_twitter_bio != "" & !is.na(castro$user_location_on_twitter_bio),]
#Get corresponding coordinates for each location of the first 200 tweets
for (name in castro_withgeo$user_location_on_twitter_bio[1:200]){ #get the coordinate data for the first 10 tweets via Google Map API.
rowid <- which(castro_withgeo$user_location_on_twitter_bio == name)
print(paste0("getting the coordinates for:", name, ", rowid is:", rowid))
Sys.sleep(1)
try(geodata <- geocode_apply(name))
if (geodata$status=="OK" & length(geodata$results)=="1") {
print(c("the lat is:", geodata$results[[1]]$geometry$location[[1]]))
print(c("the lng is:", geodata$results[[1]]$geometry$location[[2]]))
castro_withgeo[rowid,]$lat <- geodata$results[[1]]$geometry$location[[1]]
castro_withgeo[rowid,]$lng <- geodata$results[[1]]$geometry$location[[2]]
}else {
print ("skipping")
}
}
#create a separate dataframe called castro_tweets_withgeo. This dataframe contains only complete coordinates.
castro_tweets_withgeo_show <- castro_withgeo[!is.na(castro_withgeo$lat),c("lat","lng", "user_location_on_twitter_bio", "text")]
#Visualize the results using R's leaflet package
map1 <- leaflet() %>% setView(lng = -98.35, lat = 39.50, zoom = 3)
map1 <- leaflet(data = castro_tweets_withgeo_show) %>%
addTiles() %>%
setView(lng = -98.35, lat = 39.50, zoom = 4) %>%
addCircleMarkers(lng = ~lng, lat = ~lat, popup = ~ as.character(user_location_on_twitter_bio), stroke = FALSE, fillOpacity = 0.5) %>%
addProviderTiles("CartoDB.Positron")
map1
